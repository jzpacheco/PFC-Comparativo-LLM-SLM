{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5nanPaa6w9SKzkya7TOAS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FPXuvJodL6nY"},"outputs":[],"source":["!pip install torch datasets tdqm transformers peft"]},{"cell_type":"code","source":["import torch\n","import time\n","import os\n","from datasets import load_dataset\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from peft import PeftModel\n","import json"],"metadata":{"id":"wChSQeG5MpOZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 1. Configuration ---\n","base_model_name = \"microsoft/phi-3-mini-4k-instruct\"\n","# --- !! SET YOUR ADAPTER PATH !! ---\n","adapter_path = \"/content/drive/MyDrive/my-phi3-json-adapter\" # CHANGE THIS\n","test_dataset_path = \"test_json_extraction.jsonl\"\n","output_results_filename = \"results_slm_tuned_task2.jsonl\" # Output file\n","\n","# Optional: Google Drive path\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# output_base_path = \"/content/drive/MyDrive/\"\n","output_base_path = \"./\"\n","output_results_filepath = os.path.join(output_base_path, output_results_filename)\n","\n","# Check GPU\n","if not torch.cuda.is_available():\n","    raise SystemError(\"GPU not available.\")\n","print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")"],"metadata":{"id":"hHcoE64zOYDi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 2. Load Base Model and Tokenizer (Quantized) ---\n","print(\"Loading base model and tokenizer (4-bit)...\")\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n",")\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    base_model_name,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    trust_remote_code=True,\n",")\n","tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"left\""],"metadata":{"id":"6REDh-QKOa2N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 3. Load Fine-Tuned Adapter ---\n","print(f\"Loading adapter from: {adapter_path}\")\n","model = PeftModel.from_pretrained(base_model, adapter_path)\n","# model = model.merge_and_unload() # Optional merge\n","model.eval()\n","print(\"Using FINE-TUNED model for inference.\")"],"metadata":{"id":"XW8C9WoZOc5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 4. Load Test Data ---\n","print(f\"Loading test dataset from: {test_dataset_path}\")\n","try:\n","    test_dataset = load_dataset(\"json\", data_files=test_dataset_path, split=\"train\")\n","    print(f\"Test dataset loaded with {len(test_dataset)} examples.\")\n","    required_cols = ['formatted_prompt', 'ground_truth_json', 'schema']\n","    if not all(col in test_dataset.column_names for col in required_cols):\n","         raise ValueError(f\"Test file missing required columns: {required_cols}\")\n","except Exception as e:\n","    print(f\"Error loading test dataset: {e}\")\n","    raise"],"metadata":{"id":"7uBMDAsZOgJA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 5. Function to Run Inference (Tuned Model) ---\n","@torch.inference_mode()\n","def get_tuned_slm_json_output(prompt_text):\n","    # Tuned model expects the full prompt including <s>[INST]...[/INST]\n","    input_prompt = prompt_text.split(\"</s>\")[0] + \"</s>\" # Ensure it ends correctly before generation\n","\n","    inputs = tokenizer(input_prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024).to(\"cuda\")\n","\n","    start_time = time.time()\n","    outputs = model.generate(\n","        **inputs,\n","        max_new_tokens=512, # Allow space for JSON\n","        eos_token_id=tokenizer.eos_token_id,\n","        pad_token_id=tokenizer.pad_token_id,\n","        do_sample=False,\n","    )\n","    end_time = time.time()\n","    latency = end_time - start_time\n","\n","    input_token_len = inputs.input_ids.shape[1]\n","    generated_text = tokenizer.decode(outputs[0][input_token_len:], skip_special_tokens=True)\n","    cleaned_response = generated_text.strip()\n","\n","    # Attempt to find the JSON part (tuned model should be better)\n","    json_output = None\n","    try:\n","        # Fine-tuned model ideally outputs JSON directly\n","        start_brace = cleaned_response.find('{')\n","        end_brace = cleaned_response.rfind('}')\n","        if start_brace != -1 and end_brace != -1 and end_brace > start_brace:\n","            potential_json = cleaned_response[start_brace : end_brace + 1]\n","            json.loads(potential_json) # Validate\n","            json_output = potential_json\n","        # No fallback to markdown needed ideally, but keep if you see issues\n","        # else: ... check for ```json ... ```\n","\n","    except (json.JSONDecodeError, Exception) as e:\n","        pass # Handle invalid/missing JSON during evaluation\n","\n","    return json_output, latency, cleaned_response"],"metadata":{"id":"o9uT7HonOh9a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 6. Run Evaluation Loop ---\n","results = []\n","print(\"\\nStarting evaluation for FINE-TUNED SLM - Task 2...\")\n","for example in tqdm(test_dataset):\n","    prompt = example['formatted_prompt']\n","    ground_truth = example['ground_truth_json']\n","    schema = example['schema']\n","\n","    predicted_json_str, latency, raw_response = get_tuned_slm_json_output(prompt)\n","\n","    results.append({\n","        \"schema\": schema,\n","        \"ground_truth\": ground_truth,\n","        \"predicted_json_str\": predicted_json_str,\n","        \"latency\": latency,\n","        \"raw_response\": raw_response\n","    })\n","\n","print(\"\\nEvaluation complete.\")"],"metadata":{"id":"Qa34cRXfOj3D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 7. Save Results ---\n","print(f\"Saving raw results to: {output_results_filepath}\")\n","try:\n","    with open(output_results_filepath, 'w', encoding='utf-8') as f:\n","        for item in results:\n","            item_to_save = item.copy()\n","            item_to_save['ground_truth'] = json.dumps(item_to_save['ground_truth'], ensure_ascii=False)\n","            f.write(json.dumps(item_to_save, ensure_ascii=False) + '\\n')\n","    print(f\"Successfully saved {len(results)} results.\")\n","except Exception as e:\n","    print(f\"Error saving results file: {e}\")"],"metadata":{"id":"gD7bqDG1OlTu"},"execution_count":null,"outputs":[]}]}